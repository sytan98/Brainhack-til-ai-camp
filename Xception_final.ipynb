{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MOcCwsxfR30G"
   },
   "source": [
    "**Mounting Google Drive and changing directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "DqNmtqcwR2Ps",
    "outputId": "bd07d46f-6989-413c-e497-c781257d8b22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LiZyg6zYSOOg"
   },
   "outputs": [],
   "source": [
    "%cd '/content/drive/My Drive/til-ai-camp/baseline_code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2SL94IyvFwuz"
   },
   "outputs": [],
   "source": [
    "os.chdir('/content/drive/My Drive/W.A.S.D Warriors/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "62EE4dk9Zw-M"
   },
   "source": [
    "## Download and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "kzEr2gZ05RHX",
    "outputId": "e7ea9600-ca3b-4ea4-e7ac-d2fcf3f6c329"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  train_new  train_new_combined  val\n"
     ]
    }
   ],
   "source": [
    "# Creating two directories - \"data\" and \"data/trainset_11classes_0_00000\" \n",
    "#!mkdir data && mkdir data/trainset_11classes_0_00000\n",
    "# Downloading the ai-camp competition dataset\n",
    "#!wget -N https://ai-camp.s3-us-west-2.amazonaws.com/trainset_11classes_0_00000.zip\n",
    "# Unzip the data into the folder \"data/trainset_11classes_0_00000\"\n",
    "#!unzip -qq -n trainset_11classes_0_00000.zip -d data/trainset_11classes_0_00000\n",
    "# Switch directory to \"data/trainset_11classes_0_00000\" and show its content\n",
    "!cd data/trainset_11classes_0_00000 && ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4YPMa22yaJA-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_dir = 'data/trainset_11classes_0_00000'\n",
    "\n",
    "# Directory to our training data\n",
    "train_folder = os.path.join(base_dir, 'train_new_combined')\n",
    "\n",
    "# Directory to our validation data\n",
    "val_folder = os.path.join(base_dir, 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bVCvH_XXuTlu"
   },
   "source": [
    "Now, let's find out the total number of images we have in each `train`, `val` and `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "SIWrHBu1awaC",
    "outputId": "d10f18fe-549c-4039-9829-e01ef98734cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory, Number of files\n",
      "data/trainset_11classes_0_00000/train_new_combined 0\n",
      "data/trainset_11classes_0_00000/train_new_combined/Spiderman 101\n",
      "data/trainset_11classes_0_00000/train_new_combined/EaglePose 96\n",
      "data/trainset_11classes_0_00000/train_new_combined/HighKneel 96\n",
      "data/trainset_11classes_0_00000/train_new_combined/ChestBump 56\n",
      "data/trainset_11classes_0_00000/train_new_combined/HandShake 93\n",
      "data/trainset_11classes_0_00000/train_new_combined/HulkSmash 99\n",
      "data/trainset_11classes_0_00000/train_new_combined/HandGun 104\n",
      "data/trainset_11classes_0_00000/train_new_combined/Dabbing 101\n",
      "data/trainset_11classes_0_00000/train_new_combined/KungfuCrane 100\n",
      "data/trainset_11classes_0_00000/train_new_combined/KoreanHeart 97\n",
      "data/trainset_11classes_0_00000/train_new_combined/Salute 100\n",
      "data/trainset_11classes_0_00000/train_new_combined/WarriorPose 104\n",
      "data/trainset_11classes_0_00000/train_new_combined/KungfuSalute 102\n",
      "data/trainset_11classes_0_00000/train_new_combined/ChairPose 101\n",
      "data/trainset_11classes_0_00000/train_new_combined/ChildPose 91\n"
     ]
    }
   ],
   "source": [
    "# List folders and number of files\n",
    "print(\"Directory, Number of files\")\n",
    "for root, subdirs, files in os.walk('data/trainset_11classes_0_00000/train_new_combined'):\n",
    "    print(root, len(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_boVgbVAUcVF"
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Let's set up data generators that will read images from our source folders and convert them to float32 tensors. We'll have one generator for each training and validation folders.\n",
    "\n",
    "### Batch\n",
    "Our generators will yield batches of `32` images of size `299 x 299` and their labels.\n",
    "\n",
    "### Feature scaling\n",
    "Recall that in our MNIST/CIFAR-10 exercises, data that goes into a neural network should be normalised in a way that is easier to be processed by the network. In our case, we will preprocess our images by normalising the pixels values to be in the 0 to 1 range. This happens by dividing each pixel value by 255 and this process is known as data normalisation or rescaling.\n",
    "\n",
    "### Generator - ImageDataGenerator\n",
    "To rescale the data, we use `keras.preprocessing.image.ImageDataGenerator` class with the `rescale` parameter. This class will also allow us to instantiate generators of augmented image batches (and their labels) via `.flow_from_directory(directory)`. These generators can then be used with the Keras model methods that accept data generators as inputs such as `fit_generator`, `evaluate_generator` and `predict_generator`. We used data augmentation for the training image generator. To find out more about how to do image augmentation in keras, go [here](https://keras.io/preprocessing/image/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puLtZxOxTi6l"
   },
   "source": [
    "**Defining Random Eraser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PX_oz7Qj5bpB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.1, r_1=0.1, r_2=1/0.1, v_l=0, v_h=1, pixel_level=True):\n",
    "    def eraser(input_img):\n",
    "        img_h, img_w, img_c = input_img.shape\n",
    "        p_1 = np.random.rand()\n",
    "\n",
    "        if p_1 > p:\n",
    "            return input_img\n",
    "\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, img_w)\n",
    "            top = np.random.randint(0, img_h)\n",
    "\n",
    "            if left + w <= img_w and top + h <= img_h:\n",
    "                break\n",
    "\n",
    "        if pixel_level:\n",
    "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "        else:\n",
    "            c = np.random.uniform(v_l, v_h)\n",
    "\n",
    "        input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "        return input_img\n",
    "\n",
    "    return eraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "kXpGgyCWSF0u",
    "outputId": "8dcbe456-7d7e-4c59-cab2-d01f16046437"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing generator for train dataset\n",
      "Found 1441 images belonging to 15 classes.\n",
      "Preparing generator for validation dataset\n",
      "Found 347 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Batch size\n",
    "bs = 32\n",
    "\n",
    "# All images will be resized to this value\n",
    "image_size = (299, 299)\n",
    "\n",
    "# All images will be rescaled by 1./255. We apply data augmentation here.\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   brightness_range= [0.5,1.5],\n",
    "                                   horizontal_flip=True,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   fill_mode='nearest',\n",
    "                                   preprocessing_function=get_random_eraser(v_l=0, v_h=1),)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 32 using train_datagen generator\n",
    "print(\"Preparing generator for train dataset\")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory= train_folder, # This is the source directory for training images \n",
    "    target_size=image_size, # All images will be resized to value set in image_size\n",
    "    batch_size=bs,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Flow validation images in batches of 32 using val_datagen generator\n",
    "print(\"Preparing generator for validation dataset\")\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    directory= val_folder, \n",
    "    target_size=image_size,\n",
    "    batch_size=bs,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "udin5KXoTrmr"
   },
   "source": [
    "**Feature Extraction**\n",
    "\n",
    "1) Import Pre-trained models without dense layers\n",
    "\n",
    "2) Freeze All Layers\n",
    "\n",
    "3) Added in Dense, Dropout with regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dA7fyjjxO3bU"
   },
   "outputs": [],
   "source": [
    "from keras.applications.xception import Xception\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "\n",
    "Xcep = Xception(weights='imagenet', include_top=False)\n",
    "\n",
    "x = Xcep.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = Dense(1024,activation='relu',kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = Dropout(0.1)(x)\n",
    "predictions = Dense(15, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs = Xcep.input, outputs=predictions)\n",
    "\n",
    "for layer in Xcep.layers:\n",
    "  layer.trainable = False\n",
    "  \n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vn7-pFtZINEC"
   },
   "source": [
    "## Setting Up Checkpoints\n",
    "\n",
    "Let's setup a [checkpoint](https://keras.io/callbacks/) to help us monitor the validation accuracy as the model trains. This checkpoint will save the model with best validation accuracy seen so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kGy19EYPINVi"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "bestValidationCheckpointer = ModelCheckpoint('Xcep15.hdf5', monitor='val_acc', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O189ETDLVcRh"
   },
   "source": [
    "Train till it stagnates (~50epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2637
    },
    "colab_type": "code",
    "id": "MFZ__4PnluXY",
    "outputId": "abe8f3f3-ded4-4854-9a5f-5d46bd5acfcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "46/46 [==============================] - 651s 14s/step - loss: 8.5619 - acc: 0.0945 - val_loss: 4.3728 - val_acc: 0.1556\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.15562, saving model to Xcep15.hdf5\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 50s 1s/step - loss: 3.6129 - acc: 0.1516 - val_loss: 3.0535 - val_acc: 0.1037\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.15562\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 63s 1s/step - loss: 2.9305 - acc: 0.1923 - val_loss: 2.6704 - val_acc: 0.1988\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.15562 to 0.19885, saving model to Xcep15.hdf5\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 63s 1s/step - loss: 2.9798 - acc: 0.1767 - val_loss: 2.7391 - val_acc: 0.1787\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.19885\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 63s 1s/step - loss: 2.7847 - acc: 0.2134 - val_loss: 2.7000 - val_acc: 0.1816\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.19885\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 64s 1s/step - loss: 2.7031 - acc: 0.2490 - val_loss: 2.5204 - val_acc: 0.2680\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.19885 to 0.26801, saving model to Xcep15.hdf5\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 63s 1s/step - loss: 2.7568 - acc: 0.2121 - val_loss: 2.5714 - val_acc: 0.3141\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.26801 to 0.31412, saving model to Xcep15.hdf5\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 64s 1s/step - loss: 2.7231 - acc: 0.2454 - val_loss: 2.4692 - val_acc: 0.2565\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.31412\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 63s 1s/step - loss: 2.6495 - acc: 0.2222 - val_loss: 2.6468 - val_acc: 0.2651\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.31412\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 63s 1s/step - loss: 2.6367 - acc: 0.2576 - val_loss: 2.5766 - val_acc: 0.2277\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.31412\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 63s 1s/step - loss: 2.6257 - acc: 0.2657 - val_loss: 2.4123 - val_acc: 0.3084\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.31412\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 63s 1s/step - loss: 2.6417 - acc: 0.2386 - val_loss: 2.4921 - val_acc: 0.2450\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.31412\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 64s 1s/step - loss: 2.6171 - acc: 0.2651 - val_loss: 2.5877 - val_acc: 0.2767\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.31412\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 63s 1s/step - loss: 2.5798 - acc: 0.2780 - val_loss: 2.4667 - val_acc: 0.3285\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.31412 to 0.32853, saving model to Xcep15.hdf5\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 64s 1s/step - loss: 2.6245 - acc: 0.2623 - val_loss: 2.5270 - val_acc: 0.2392\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.32853\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 64s 1s/step - loss: 2.5344 - acc: 0.2882 - val_loss: 2.5364 - val_acc: 0.2421\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.32853\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 64s 1s/step - loss: 2.5698 - acc: 0.2746 - val_loss: 2.4061 - val_acc: 0.2853\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.32853\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 64s 1s/step - loss: 2.5122 - acc: 0.3033 - val_loss: 2.4680 - val_acc: 0.2853\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.32853\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 63s 1s/step - loss: 2.4973 - acc: 0.2807 - val_loss: 2.4776 - val_acc: 0.2882\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.32853\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 64s 1s/step - loss: 2.4239 - acc: 0.3113 - val_loss: 2.3676 - val_acc: 0.2911\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.32853\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 64s 1s/step - loss: 2.4903 - acc: 0.3401 - val_loss: 2.4863 - val_acc: 0.2392\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.32853\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 63s 1s/step - loss: 2.4571 - acc: 0.2963 - val_loss: 2.3355 - val_acc: 0.3141\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.32853\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 64s 1s/step - loss: 2.4326 - acc: 0.3133 - val_loss: 2.3567 - val_acc: 0.3112\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.32853\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 64s 1s/step - loss: 2.4169 - acc: 0.3468 - val_loss: 2.3798 - val_acc: 0.2968\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.32853\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 64s 1s/step - loss: 2.4797 - acc: 0.3045 - val_loss: 2.3308 - val_acc: 0.2997\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.32853\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 64s 1s/step - loss: 2.3939 - acc: 0.3344 - val_loss: 2.4798 - val_acc: 0.2911\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.32853\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 64s 1s/step - loss: 2.4599 - acc: 0.3079 - val_loss: 2.3973 - val_acc: 0.3199\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.32853\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 64s 1s/step - loss: 2.4471 - acc: 0.3072 - val_loss: 2.4724 - val_acc: 0.2824\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.32853\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 65s 1s/step - loss: 2.3839 - acc: 0.3092 - val_loss: 2.2070 - val_acc: 0.3775\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.32853 to 0.37752, saving model to Xcep15.hdf5\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 63s 1s/step - loss: 2.3232 - acc: 0.3570 - val_loss: 2.4834 - val_acc: 0.2709\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.37752\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 65s 1s/step - loss: 2.3466 - acc: 0.3391 - val_loss: 2.3153 - val_acc: 0.3516\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.37752\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 64s 1s/step - loss: 2.3794 - acc: 0.3317 - val_loss: 2.4916 - val_acc: 0.2450\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.37752\n",
      "Epoch 33/100\n",
      "15/46 [========>.....................] - ETA: 41s - loss: 2.2926 - acc: 0.3521"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1a5348a5072d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# validation generator has 253 validation images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbestValidationCheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     \u001b[0;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[0;32m--> 709\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[0;34m(uid)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0muid\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \"\"\"\n\u001b[0;32m--> 626\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    228\u001b[0m                            \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                            \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                            interpolation=self.interpolation)\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# Pillow images should be closed after `load_img`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    108\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    109\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 107] Transport endpoint is not connected: 'data/trainset_11classes_0_00000/train_new_combined/Spiderman/268526_206.png'"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "        train_generator, # train generator has 973 train images\n",
    "        steps_per_epoch=train_generator.samples // bs + 1,\n",
    "        epochs=100,\n",
    "        validation_data=val_generator, # validation generator has 253 validation images\n",
    "        validation_steps=val_generator.samples // bs + 1,\n",
    "        callbacks=[bestValidationCheckpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2375
    },
    "colab_type": "code",
    "id": "3UswyiF0mwUK",
    "outputId": "bbb5d4d4-35b0-400b-d824-f36f0541013f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2\n",
      "1 block1_conv1\n",
      "2 block1_conv1_bn\n",
      "3 block1_conv1_act\n",
      "4 block1_conv2\n",
      "5 block1_conv2_bn\n",
      "6 block1_conv2_act\n",
      "7 block2_sepconv1\n",
      "8 block2_sepconv1_bn\n",
      "9 block2_sepconv2_act\n",
      "10 block2_sepconv2\n",
      "11 block2_sepconv2_bn\n",
      "12 conv2d_5\n",
      "13 block2_pool\n",
      "14 batch_normalization_5\n",
      "15 add_13\n",
      "16 block3_sepconv1_act\n",
      "17 block3_sepconv1\n",
      "18 block3_sepconv1_bn\n",
      "19 block3_sepconv2_act\n",
      "20 block3_sepconv2\n",
      "21 block3_sepconv2_bn\n",
      "22 conv2d_6\n",
      "23 block3_pool\n",
      "24 batch_normalization_6\n",
      "25 add_14\n",
      "26 block4_sepconv1_act\n",
      "27 block4_sepconv1\n",
      "28 block4_sepconv1_bn\n",
      "29 block4_sepconv2_act\n",
      "30 block4_sepconv2\n",
      "31 block4_sepconv2_bn\n",
      "32 conv2d_7\n",
      "33 block4_pool\n",
      "34 batch_normalization_7\n",
      "35 add_15\n",
      "36 block5_sepconv1_act\n",
      "37 block5_sepconv1\n",
      "38 block5_sepconv1_bn\n",
      "39 block5_sepconv2_act\n",
      "40 block5_sepconv2\n",
      "41 block5_sepconv2_bn\n",
      "42 block5_sepconv3_act\n",
      "43 block5_sepconv3\n",
      "44 block5_sepconv3_bn\n",
      "45 add_16\n",
      "46 block6_sepconv1_act\n",
      "47 block6_sepconv1\n",
      "48 block6_sepconv1_bn\n",
      "49 block6_sepconv2_act\n",
      "50 block6_sepconv2\n",
      "51 block6_sepconv2_bn\n",
      "52 block6_sepconv3_act\n",
      "53 block6_sepconv3\n",
      "54 block6_sepconv3_bn\n",
      "55 add_17\n",
      "56 block7_sepconv1_act\n",
      "57 block7_sepconv1\n",
      "58 block7_sepconv1_bn\n",
      "59 block7_sepconv2_act\n",
      "60 block7_sepconv2\n",
      "61 block7_sepconv2_bn\n",
      "62 block7_sepconv3_act\n",
      "63 block7_sepconv3\n",
      "64 block7_sepconv3_bn\n",
      "65 add_18\n",
      "66 block8_sepconv1_act\n",
      "67 block8_sepconv1\n",
      "68 block8_sepconv1_bn\n",
      "69 block8_sepconv2_act\n",
      "70 block8_sepconv2\n",
      "71 block8_sepconv2_bn\n",
      "72 block8_sepconv3_act\n",
      "73 block8_sepconv3\n",
      "74 block8_sepconv3_bn\n",
      "75 add_19\n",
      "76 block9_sepconv1_act\n",
      "77 block9_sepconv1\n",
      "78 block9_sepconv1_bn\n",
      "79 block9_sepconv2_act\n",
      "80 block9_sepconv2\n",
      "81 block9_sepconv2_bn\n",
      "82 block9_sepconv3_act\n",
      "83 block9_sepconv3\n",
      "84 block9_sepconv3_bn\n",
      "85 add_20\n",
      "86 block10_sepconv1_act\n",
      "87 block10_sepconv1\n",
      "88 block10_sepconv1_bn\n",
      "89 block10_sepconv2_act\n",
      "90 block10_sepconv2\n",
      "91 block10_sepconv2_bn\n",
      "92 block10_sepconv3_act\n",
      "93 block10_sepconv3\n",
      "94 block10_sepconv3_bn\n",
      "95 add_21\n",
      "96 block11_sepconv1_act\n",
      "97 block11_sepconv1\n",
      "98 block11_sepconv1_bn\n",
      "99 block11_sepconv2_act\n",
      "100 block11_sepconv2\n",
      "101 block11_sepconv2_bn\n",
      "102 block11_sepconv3_act\n",
      "103 block11_sepconv3\n",
      "104 block11_sepconv3_bn\n",
      "105 add_22\n",
      "106 block12_sepconv1_act\n",
      "107 block12_sepconv1\n",
      "108 block12_sepconv1_bn\n",
      "109 block12_sepconv2_act\n",
      "110 block12_sepconv2\n",
      "111 block12_sepconv2_bn\n",
      "112 block12_sepconv3_act\n",
      "113 block12_sepconv3\n",
      "114 block12_sepconv3_bn\n",
      "115 add_23\n",
      "116 block13_sepconv1_act\n",
      "117 block13_sepconv1\n",
      "118 block13_sepconv1_bn\n",
      "119 block13_sepconv2_act\n",
      "120 block13_sepconv2\n",
      "121 block13_sepconv2_bn\n",
      "122 conv2d_8\n",
      "123 block13_pool\n",
      "124 batch_normalization_8\n",
      "125 add_24\n",
      "126 block14_sepconv1\n",
      "127 block14_sepconv1_bn\n",
      "128 block14_sepconv1_act\n",
      "129 block14_sepconv2\n",
      "130 block14_sepconv2_bn\n",
      "131 block14_sepconv2_act\n",
      "132 global_average_pooling2d_2\n",
      "133 dense_3\n",
      "134 dropout_2\n",
      "135 dense_4\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "  print(i, layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5H3gdcxaUOYH"
   },
   "source": [
    "**Unfreezing Layers for Fine-Tuning** \n",
    "\n",
    "Choose to unfreeze about 2/3 of the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EEa7ZmoRnjjU"
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[:56]:\n",
    "  layer.trainable = False\n",
    "for layer in model.layers[56:]:\n",
    "  layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Av-Mk7KZKD7Q"
   },
   "source": [
    "Let's summarise the model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1949
    },
    "colab_type": "code",
    "id": "eEwSI4-FKDg4",
    "outputId": "41625269-3e26-4e96-fb27-b9be36dffb30"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Type</th>\n",
       "      <th>Layer Name</th>\n",
       "      <th>Layer Trainable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;keras.engine.input_layer.InputLayer object at...</td>\n",
       "      <td>input_2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0...</td>\n",
       "      <td>block1_conv1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization...</td>\n",
       "      <td>block1_conv1_bn</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;keras.layers.core.Activation object at 0x7fad...</td>\n",
       "      <td>block1_conv1_act</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0...</td>\n",
       "      <td>block1_conv2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization...</td>\n",
       "      <td>block1_conv2_bn</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;keras.layers.core.Activation object at 0x7fad...</td>\n",
       "      <td>block1_conv2_act</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;keras.layers.convolutional.SeparableConv2D ob...</td>\n",
       "      <td>block2_sepconv1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization...</td>\n",
       "      <td>block2_sepconv1_bn</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;keras.layers.core.Activation object at 0x7fad...</td>\n",
       "      <td>block2_sepconv2_act</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;keras.layers.convolutional.SeparableConv2D ob...</td>\n",
       "      <td>block2_sepconv2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization...</td>\n",
       "      <td>block2_sepconv2_bn</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0...</td>\n",
       "      <td>conv2d_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0...</td>\n",
       "      <td>block2_pool</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization...</td>\n",
       "      <td>batch_normalization_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;keras.layers.merge.Add object at 0x7fadd4edb588&gt;</td>\n",
       "      <td>add_13</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&lt;keras.layers.core.Activation object at 0x7fad...</td>\n",
       "      <td>block3_sepconv1_act</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;keras.layers.convolutional.SeparableConv2D ob...</td>\n",
       "      <td>block3_sepconv1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization...</td>\n",
       "      <td>block3_sepconv1_bn</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;keras.layers.core.Activation object at 0x7fad...</td>\n",
       "      <td>block3_sepconv2_act</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>&lt;keras.layers.convolutional.SeparableConv2D ob...</td>\n",
       "      <td>block3_sepconv2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization...</td>\n",
       "      <td>block3_sepconv2_bn</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0...</td>\n",
       "      <td>conv2d_6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0...</td>\n",
       "      <td>block3_pool</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization...</td>\n",
       "      <td>batch_normalization_6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>&lt;keras.layers.merge.Add object at 0x7fadd42fe160&gt;</td>\n",
       "      <td>add_14</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>&lt;keras.layers.core.Activation object at 0x7fad...</td>\n",
       "      <td>block4_sepconv1_act</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>&lt;keras.layers.convolutional.SeparableConv2D ob...</td>\n",
       "      <td>block4_sepconv1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization...</td>\n",
       "      <td>block4_sepconv1_bn</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>&lt;keras.layers.core.Activation object at 0x7fad...</td>\n",
       "      <td>block4_sepconv2_act</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>&lt;keras.layers.core.Activation object at 0x7fad...</td>\n",
       "      <td>block12_sepconv1_act</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>&lt;keras.layers.convolutional.SeparableConv2D ob...</td>\n",
       "      <td>block12_sepconv1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization...</td>\n",
       "      <td>block12_sepconv1_bn</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>&lt;keras.layers.core.Activation object at 0x7fad...</td>\n",
       "      <td>block12_sepconv2_act</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>&lt;keras.layers.convolutional.SeparableConv2D ob...</td>\n",
       "      <td>block12_sepconv2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization...</td>\n",
       "      <td>block12_sepconv2_bn</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>&lt;keras.layers.core.Activation object at 0x7fad...</td>\n",
       "      <td>block12_sepconv3_act</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>&lt;keras.layers.convolutional.SeparableConv2D ob...</td>\n",
       "      <td>block12_sepconv3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization...</td>\n",
       "      <td>block12_sepconv3_bn</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>&lt;keras.layers.merge.Add object at 0x7fadbb95cc88&gt;</td>\n",
       "      <td>add_23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>&lt;keras.layers.core.Activation object at 0x7fad...</td>\n",
       "      <td>block13_sepconv1_act</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>&lt;keras.layers.convolutional.SeparableConv2D ob...</td>\n",
       "      <td>block13_sepconv1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization...</td>\n",
       "      <td>block13_sepconv1_bn</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>&lt;keras.layers.core.Activation object at 0x7fad...</td>\n",
       "      <td>block13_sepconv2_act</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>&lt;keras.layers.convolutional.SeparableConv2D ob...</td>\n",
       "      <td>block13_sepconv2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization...</td>\n",
       "      <td>block13_sepconv2_bn</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0...</td>\n",
       "      <td>conv2d_8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0...</td>\n",
       "      <td>block13_pool</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization...</td>\n",
       "      <td>batch_normalization_8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>&lt;keras.layers.merge.Add object at 0x7fadb9afb2b0&gt;</td>\n",
       "      <td>add_24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>&lt;keras.layers.convolutional.SeparableConv2D ob...</td>\n",
       "      <td>block14_sepconv1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization...</td>\n",
       "      <td>block14_sepconv1_bn</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>&lt;keras.layers.core.Activation object at 0x7fad...</td>\n",
       "      <td>block14_sepconv1_act</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>&lt;keras.layers.convolutional.SeparableConv2D ob...</td>\n",
       "      <td>block14_sepconv2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>&lt;keras.layers.normalization.BatchNormalization...</td>\n",
       "      <td>block14_sepconv2_bn</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>&lt;keras.layers.core.Activation object at 0x7fad...</td>\n",
       "      <td>block14_sepconv2_act</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>&lt;keras.layers.pooling.GlobalAveragePooling2D o...</td>\n",
       "      <td>global_average_pooling2d_2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>&lt;keras.layers.core.Dense object at 0x7fadb987b...</td>\n",
       "      <td>dense_3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>&lt;keras.layers.core.Dropout object at 0x7fadb98...</td>\n",
       "      <td>dropout_2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>&lt;keras.layers.core.Dense object at 0x7fadb90ed...</td>\n",
       "      <td>dense_4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Layer Type  ... Layer Trainable\n",
       "0    <keras.engine.input_layer.InputLayer object at...  ...           False\n",
       "1    <keras.layers.convolutional.Conv2D object at 0...  ...           False\n",
       "2    <keras.layers.normalization.BatchNormalization...  ...           False\n",
       "3    <keras.layers.core.Activation object at 0x7fad...  ...           False\n",
       "4    <keras.layers.convolutional.Conv2D object at 0...  ...           False\n",
       "5    <keras.layers.normalization.BatchNormalization...  ...           False\n",
       "6    <keras.layers.core.Activation object at 0x7fad...  ...           False\n",
       "7    <keras.layers.convolutional.SeparableConv2D ob...  ...           False\n",
       "8    <keras.layers.normalization.BatchNormalization...  ...           False\n",
       "9    <keras.layers.core.Activation object at 0x7fad...  ...           False\n",
       "10   <keras.layers.convolutional.SeparableConv2D ob...  ...           False\n",
       "11   <keras.layers.normalization.BatchNormalization...  ...           False\n",
       "12   <keras.layers.convolutional.Conv2D object at 0...  ...           False\n",
       "13   <keras.layers.pooling.MaxPooling2D object at 0...  ...           False\n",
       "14   <keras.layers.normalization.BatchNormalization...  ...           False\n",
       "15   <keras.layers.merge.Add object at 0x7fadd4edb588>  ...           False\n",
       "16   <keras.layers.core.Activation object at 0x7fad...  ...           False\n",
       "17   <keras.layers.convolutional.SeparableConv2D ob...  ...           False\n",
       "18   <keras.layers.normalization.BatchNormalization...  ...           False\n",
       "19   <keras.layers.core.Activation object at 0x7fad...  ...           False\n",
       "20   <keras.layers.convolutional.SeparableConv2D ob...  ...           False\n",
       "21   <keras.layers.normalization.BatchNormalization...  ...           False\n",
       "22   <keras.layers.convolutional.Conv2D object at 0...  ...           False\n",
       "23   <keras.layers.pooling.MaxPooling2D object at 0...  ...           False\n",
       "24   <keras.layers.normalization.BatchNormalization...  ...           False\n",
       "25   <keras.layers.merge.Add object at 0x7fadd42fe160>  ...           False\n",
       "26   <keras.layers.core.Activation object at 0x7fad...  ...           False\n",
       "27   <keras.layers.convolutional.SeparableConv2D ob...  ...           False\n",
       "28   <keras.layers.normalization.BatchNormalization...  ...           False\n",
       "29   <keras.layers.core.Activation object at 0x7fad...  ...           False\n",
       "..                                                 ...  ...             ...\n",
       "106  <keras.layers.core.Activation object at 0x7fad...  ...            True\n",
       "107  <keras.layers.convolutional.SeparableConv2D ob...  ...            True\n",
       "108  <keras.layers.normalization.BatchNormalization...  ...            True\n",
       "109  <keras.layers.core.Activation object at 0x7fad...  ...            True\n",
       "110  <keras.layers.convolutional.SeparableConv2D ob...  ...            True\n",
       "111  <keras.layers.normalization.BatchNormalization...  ...            True\n",
       "112  <keras.layers.core.Activation object at 0x7fad...  ...            True\n",
       "113  <keras.layers.convolutional.SeparableConv2D ob...  ...            True\n",
       "114  <keras.layers.normalization.BatchNormalization...  ...            True\n",
       "115  <keras.layers.merge.Add object at 0x7fadbb95cc88>  ...            True\n",
       "116  <keras.layers.core.Activation object at 0x7fad...  ...            True\n",
       "117  <keras.layers.convolutional.SeparableConv2D ob...  ...            True\n",
       "118  <keras.layers.normalization.BatchNormalization...  ...            True\n",
       "119  <keras.layers.core.Activation object at 0x7fad...  ...            True\n",
       "120  <keras.layers.convolutional.SeparableConv2D ob...  ...            True\n",
       "121  <keras.layers.normalization.BatchNormalization...  ...            True\n",
       "122  <keras.layers.convolutional.Conv2D object at 0...  ...            True\n",
       "123  <keras.layers.pooling.MaxPooling2D object at 0...  ...            True\n",
       "124  <keras.layers.normalization.BatchNormalization...  ...            True\n",
       "125  <keras.layers.merge.Add object at 0x7fadb9afb2b0>  ...            True\n",
       "126  <keras.layers.convolutional.SeparableConv2D ob...  ...            True\n",
       "127  <keras.layers.normalization.BatchNormalization...  ...            True\n",
       "128  <keras.layers.core.Activation object at 0x7fad...  ...            True\n",
       "129  <keras.layers.convolutional.SeparableConv2D ob...  ...            True\n",
       "130  <keras.layers.normalization.BatchNormalization...  ...            True\n",
       "131  <keras.layers.core.Activation object at 0x7fad...  ...            True\n",
       "132  <keras.layers.pooling.GlobalAveragePooling2D o...  ...            True\n",
       "133  <keras.layers.core.Dense object at 0x7fadb987b...  ...            True\n",
       "134  <keras.layers.core.Dropout object at 0x7fadb98...  ...            True\n",
       "135  <keras.layers.core.Dense object at 0x7fadb90ed...  ...            True\n",
       "\n",
       "[136 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in model.layers]\n",
    "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5jFT6kbPZ_Wi"
   },
   "source": [
    "**Change Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Xmx5IvQZ4oK"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.001, momentum=0.9, decay=1e-11),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T0rPDjqYaEmq"
   },
   "source": [
    "## Model Training \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "colab_type": "code",
    "id": "bzU1gNrcTPX3",
    "outputId": "c1e5b0a2-2661-4dd3-cf4f-65b18d495431"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "46/46 [==============================] - 74s 2s/step - loss: 0.3989 - acc: 0.9182 - val_loss: 1.3363 - val_acc: 0.6830\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.79539\n",
      "Epoch 2/200\n",
      "46/46 [==============================] - 69s 2s/step - loss: 0.5011 - acc: 0.8747 - val_loss: 1.2785 - val_acc: 0.6945\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.79539\n",
      "Epoch 3/200\n",
      "46/46 [==============================] - 69s 1s/step - loss: 0.5252 - acc: 0.8842 - val_loss: 1.8054 - val_acc: 0.5937\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.79539\n",
      "Epoch 4/200\n",
      "36/46 [======================>.......] - ETA: 13s - loss: 0.5184 - acc: 0.8819"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-695d638e56b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# validation generator has 253 validation images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbestValidationCheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "        train_generator, # train generator has 973 train images\n",
    "        steps_per_epoch=train_generator.samples // bs + 1,\n",
    "        epochs=200,\n",
    "        validation_data=val_generator, # validation generator has 253 validation images\n",
    "        validation_steps=val_generator.samples // bs + 1,\n",
    "        callbacks=[bestValidationCheckpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LNSwAgJcUgl0"
   },
   "source": [
    "**Plotting Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zp0yy4M9JMLm"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Xception_final.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
