{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DSSlzY5Cb-V8"
   },
   "source": [
    "## Mounting Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "o9beYk1sfSN1",
    "outputId": "89e243df-c207-4061-a3fb-f540a24098ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GkVO9pQ-fm2r"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/drive/My Drive/W.A.S.D Warriors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 835
    },
    "colab_type": "code",
    "id": "rixsEzM7fskE",
    "outputId": "82a86d27-6c06-448d-c337-96674ac25841"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting folium==0.2.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/dd/75ced7437bfa7cb9a88b96ee0177953062803c3b4cde411a97d98c35adaf/folium-0.2.1.tar.gz (69kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 5.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: Jinja2 in /usr/local/lib/python3.6/dist-packages (from folium==0.2.1) (2.10.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2->folium==0.2.1) (1.1.1)\n",
      "Building wheels for collected packages: folium\n",
      "  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /root/.cache/pip/wheels/b8/09/f0/52d2ef419c2aaf4fb149f92a33e0008bdce7ae816f0dd8f0c5\n",
      "Successfully built folium\n",
      "Installing collected packages: folium\n",
      "  Found existing installation: folium 0.8.3\n",
      "    Uninstalling folium-0.8.3:\n",
      "      Successfully uninstalled folium-0.8.3\n",
      "Successfully installed folium-0.2.1\n",
      "Collecting imgaug==0.2.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/60/a06a48d85a7e9062f5870347a3e3e953da30b37928d43b380c949bca458a/imgaug-0.2.5.tar.gz (562kB)\n",
      "\u001b[K     |████████████████████████████████| 563kB 6.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.5) (1.3.0)\n",
      "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.5) (0.15.0)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.5) (1.16.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.5) (1.12.0)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (4.3.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (1.0.3)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (2.3)\n",
      "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (2.4.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (3.0.3)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image>=0.11.0->imgaug==0.2.5) (0.46)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug==0.2.5) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (2.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (2.5.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (41.0.1)\n",
      "Building wheels for collected packages: imgaug\n",
      "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /root/.cache/pip/wheels/31/48/c8/ca3345e8582a078de94243996e148377ef66fdb845557bae0b\n",
      "Successfully built imgaug\n",
      "Installing collected packages: imgaug\n",
      "  Found existing installation: imgaug 0.2.9\n",
      "    Uninstalling imgaug-0.2.9:\n",
      "      Successfully uninstalled imgaug-0.2.9\n",
      "Successfully installed imgaug-0.2.5\n",
      "\u001b[K     |████████████████████████████████| 17.3MB 6.9MB/s \n",
      "\u001b[K     |████████████████████████████████| 2.0MB 37.6MB/s \n",
      "\u001b[?25h  Building wheel for pprint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install folium==0.2.1\n",
    "!pip install imgaug==0.2.5\n",
    "\n",
    "!pip install --force-reinstall --user --no-warn-script-location -q https://ai-camp.s3-us-west-2.amazonaws.com/AiCampEval-1.7-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0SAMQjrAcFQK"
   },
   "source": [
    "##Use AiCampEval to import eval_submit\n",
    "Reset if unable to get below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PrXK65wRfvEI"
   },
   "outputs": [],
   "source": [
    "from AiCampEval import eval_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k_O5YzzJ5Afx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_dir = 'data/trainset_11classes_0_00000'\n",
    "\n",
    "# Directory to our training data\n",
    "train_folder = os.path.join(base_dir, 'train')\n",
    "\n",
    "# Directory to our validation data\n",
    "val_folder = os.path.join(base_dir, 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oBn5slf0cLaE"
   },
   "source": [
    "##Load Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "w1iAFeHffxUp",
    "outputId": "fcf8a219-fd6f-4a1c-ffe5-c0b0d327745e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 83.43276333808899\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import os\n",
    "import time\n",
    "\n",
    "os.chdir('/drive/My Drive/W.A.S.D Warriors')\n",
    "\n",
    "st = time.time()\n",
    "model_path = 'Xcep15_0.79(previous).hdf5'\n",
    "model = load_model( model_path )\n",
    "print('Time taken: ' + str(time.time()-st))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kdbcuvDCQKOI"
   },
   "source": [
    "##PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "qULQ6T5EhMBM",
    "outputId": "cd52df6b-2b73-4972-d66d-084e59060dc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1441 images belonging to 15 classes.\n",
      "{'ChairPose': 0, 'ChestBump': 1, 'ChildPose': 2, 'Dabbing': 3, 'EaglePose': 4, 'HandGun': 5, 'HandShake': 6, 'HighKneel': 7, 'HulkSmash': 8, 'KoreanHeart': 9, 'KungfuCrane': 10, 'KungfuSalute': 11, 'Salute': 12, 'Spiderman': 13, 'WarriorPose': 14}\n",
      "Preparing generator for validation dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = 'data/trainset_11classes_0_00000'\n",
    "train_folder = os.path.join(base_dir, 'train_new_combined')\n",
    "\n",
    "num_models = 1\n",
    "\n",
    "# Batch size\n",
    "bs = 32\n",
    "\n",
    "# All images will be resized to this value\n",
    "image_size = (299, 299)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   brightness_range= [0.5,1.5],\n",
    "                                   horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory= train_folder, # This is the source directory for training images \n",
    "    target_size=image_size, # All images will be resized to value set in image_size\n",
    "    batch_size=bs,\n",
    "    class_mode='categorical')\n",
    "\n",
    "print(train_generator.class_indices)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "def generate_generator_multiple(generator, num_model, directory, bs, image_size):\n",
    "  generator1 = generator.flow_from_directory(\n",
    "      directory= directory, # This is the source directory for training images \n",
    "      target_size=image_size, # All images will be resized to value set in image_size\n",
    "      batch_size=bs,\n",
    "      class_mode='categorical')\n",
    "  \n",
    "  while True:\n",
    "    generator = generator1.next()\n",
    "    x_input = []\n",
    "    \n",
    "    for i in range(num_model):\n",
    "      x_input.append(generator[0])\n",
    "    \n",
    "    y_input = generator[1]\n",
    "    \n",
    "    yield x_input, y_input  #Yield both images and their mutual label\n",
    "\n",
    "\n",
    "# Flow validation images in batches of 32 using val_datagen generator\n",
    "print(\"Preparing generator for validation dataset\")\n",
    "val_generator = generate_generator_multiple(val_datagen, num_models, val_folder, bs, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b6y1PhPThRnI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "ensemble = False\n",
    "num_models = 1\n",
    "\n",
    "'''\n",
    "This is a helper function to preprocess the input before sending it through my network. \n",
    "It performs the following steps:\n",
    "1. Resizes each image to (224,224,3), which are the image dimensions my model was trained on.\n",
    "2. Normalizes the range of each pixel's value from [0-255] to [0-1].\n",
    "3. Reshapes each array such that it has a batch dimension: from  (224,224,3) -> (1,224,224,3), \n",
    "because my model.predict function expects a batch dimension.\n",
    "\n",
    "Implement your own preprocessing function according to your model's needs.\n",
    "''' \n",
    "def preprocess_arrays(list_of_np_arrays):\n",
    "    target_size = image_size\n",
    "    pil_images = [ Image.fromarray(arr.astype('uint8'), 'RGB') for arr in list_of_np_arrays ]\n",
    "    resized_pil_images = [img.resize( target_size, Image.NEAREST ) for img in pil_images]\n",
    "    resized_images = [np.array( img ) for img in resized_pil_images]\n",
    "    \n",
    "    if ensemble == False:\n",
    "      preprocessed_images = [np.expand_dims(x, axis=0) / 255. for x in resized_images]\n",
    "      return preprocessed_images\n",
    "    else:\n",
    "      preprocessed_images = [np.expand_dims(x, axis=0) / 255. for x in resized_images]\n",
    "      x_input = []\n",
    "\n",
    "      for i in range(len(preprocessed_images)):\n",
    "        x = [preprocessed_images[i] for _ in range(num_models)]\n",
    "        x_input.append(x)\n",
    "\n",
    "      return x_input\n",
    "\n",
    "'''\n",
    "This function accepts a list of numpy array images as input and outputs a list of prediction strings \n",
    "corresponding to each image in the input list.\n",
    "IMPORTANT: you have to implement this function.\n",
    "''' \n",
    "def evaluate_images(list_of_np_arrays):\n",
    "    # Swap the key and value in the class_indices\n",
    "    label_dict = dict((v,k) for k,v in (train_generator.class_indices).items())\n",
    "    # Run through the list_of_np_arrays to perform any preprocessing you need\n",
    "    preprocessed_imgs = preprocess_arrays( list_of_np_arrays )\n",
    "    # Get a list of softmax_vectors by passing in the preprocessed_imgs to model.predict()\n",
    "    softmax_vectors = [ model.predict( x )[0]  for x in preprocessed_imgs]\n",
    "    # Get the predicted_class_indices by running each of the softmax_vectors through np.argmax()\n",
    "    predicted_class_indices = [ np.argmax( x ) for x in softmax_vectors ]\n",
    "    # Convert the list of class_indices to a list of predictions (in str)\n",
    "    # predictions is a list of labels: ['KoreanHeart', 'KoreanHeart','ChairPose',.......]\n",
    "    predictions = [ label_dict[k] for k in predicted_class_indices ]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hHcffDXVQN33"
   },
   "source": [
    "##Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "AAjlfFrghV2_",
    "outputId": "6bacf271-5290-4cc2-8e6f-5d0c8b8471be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beginning file download of test images\n",
      "\n",
      "Time taken for download: 67.880s\n",
      "\n",
      "Predicting batch 1/4...\n",
      "\n",
      "Predicting batch 2/4...\n",
      "\n",
      "Predicting batch 3/4...\n",
      "\n",
      "Predicting batch 4/4...\n",
      "\n",
      "Total time taken for model evaluation: 153.503s\n",
      "\n",
      "Submitting predictions\n",
      "{'accuracy': 0.7812,\n",
      " 'submission_time': '2019-06-13 17:41:21.554828+08:00',\n",
      " 'submission_type': 'thefinaltest_4_88888',\n",
      " 'team_id': 'W.A.S.D Warriors'}\n"
     ]
    }
   ],
   "source": [
    "TEAM_ID = \"W.A.S.D Warriors\"\n",
    "SUBMISSION_TYPE = \"thefinaltest_4_88888\"\n",
    "\n",
    "eval_submit(evaluate_images, SUBMISSION_TYPE, TEAM_ID )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j6mKFNnFckpy"
   },
   "source": [
    "For normal val_generator evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0exM48784uYF"
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate_generator(val_generator, steps=253 // 32 + 1, verbose=1)\n",
    "print('Val loss:', scores[0])\n",
    "print('Val accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Evaluation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
